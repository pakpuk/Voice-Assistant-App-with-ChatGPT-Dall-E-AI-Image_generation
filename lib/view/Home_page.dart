import 'dart:convert';

import 'package:flutter/material.dart';
import 'package:speech_to_text/speech_recognition_result.dart';
import 'package:speech_to_text/speech_to_text.dart';
import 'package:voice_assistant_app/componants/box_feature.dart';
import 'package:voice_assistant_app/componants/profile_widget.dart';
import 'package:voice_assistant_app/componants/wlc_message_widget.dart';
import 'package:voice_assistant_app/service/gemini_service.dart';

import 'package:voice_assistant_app/theming/colors.dart';
import 'package:voice_assistant_app/utils/constants.dart';

class HomePage extends StatefulWidget {
  const HomePage({super.key});

  @override
  State<HomePage> createState() => _HomePageState();
}

class _HomePageState extends State<HomePage> {
  final speechToText = SpeechToText();
  String lastWords = '';
  @override
  void initState() {
    super.initState();
    initSpeechToText();
  }

  Future<void> initSpeechToText() async {
    await speechToText.initialize();
    setState(() {});
  }

  Future<void> startListening() async {
    await speechToText.listen(onResult: onSpeechResult);
    setState(() {});
  }

  Future<void> stopListening() async {
    await speechToText.stop();
    setState(() {});
  }

  void onSpeechResult(SpeechRecognitionResult result) {
    setState(() {
      lastWords = result.recognizedWords;
    });
  }

  @override
  void dispose() {
    speechToText.stop();
    super.dispose();
  }

  Widget build(BuildContext context) {
    final screenWidth = MediaQuery.of(context).size.width;
    final screenHeight = MediaQuery.of(context).size.height;

    return Scaffold(
      appBar: AppBar(
        backgroundColor: Pallete.whiteColor,
        title: Text(Constants.Appbartitle),
        centerTitle: true,
        leading: Icon(Icons.menu),
      ),
      body: SingleChildScrollView(
        child: Column(
          children: [
            Center(
              child: ProfileWidget(),
            ),
            SizedBox(
              height: screenHeight * 0.02,
            ),
            WlcMessageWidget(),
            SizedBox(
              height: screenHeight * 0.02,
            ),
            Container(
              padding: EdgeInsets.all(screenWidth * 0.025),
              margin: EdgeInsets.only(left: screenWidth * 0.05),
              child: Align(
                alignment: Alignment.centerLeft,
                child: Text(
                  Constants.featureTitle,
                  style: TextStyle(
                    fontFamily: 'Cera Pro',
                    color: Pallete.mainFontColor,
                    fontSize: screenWidth * 0.05,
                    fontWeight: FontWeight.bold,
                  ),
                ),
              ),
            ),
            Column(
              children: [
                BoxFeature(
                  boxcolor: Pallete.firstSuggestionBoxColor,
                  boxtitle: Constants.firsbxtitl,
                  boxsubtitle: Constants.firsboxsubtitle,
                ),
                BoxFeature(
                  boxcolor: Pallete.secondSuggestionBoxColor,
                  boxtitle: Constants.scnbxtitl,
                  boxsubtitle: Constants.secnboxsubtitle,
                ),
                BoxFeature(
                  boxcolor: Pallete.thirdSuggestionBoxColor,
                  boxtitle: Constants.firsbxtitl,
                  boxsubtitle: Constants.thirdboxsubtitle,
                )
              ],
            )
          ],
        ),
      ),
      floatingActionButton: FloatingActionButton(
        onPressed: () async {
          if (await speechToText.hasPermission && speechToText.isNotListening) {
            // Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø¹Ø·Ù‰ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…Ø§ÙŠÙƒ ÙˆÙ„Ù… ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ØŒ Ù†Ø¨Ø¯Ø£ Ù†Ø³ØªÙ…Ø¹
            await startListening();
          } else if (speechToText.isListening) {
            // Ø¥Ø°Ø§ ÙƒÙ†Ø§ Ù†Ø³ØªÙ…Ø¹ Ø§Ù„Ø¢Ù†ØŒ Ù†ÙˆÙ‚Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
            await stopListening();

            if (lastWords.isNotEmpty) {
              // Ø¥Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ù„ Ø­Ø§Ø¬Ø© (lastWords ÙÙŠÙ‡ ÙƒÙ„Ø§Ù…)
              final response = await GeminiService.getGeminiResponse(lastWords);

              // Ù†ØªØ£ÙƒØ¯ Ù‡Ù„ Ø§Ù„Ø±Ø¯ ØµÙˆØ±Ø© ÙˆÙ„Ø§ Ù†Øµ (Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ base64 Ø£Ùˆ Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø±ÙˆÙØ©)
              final isImage = response.contains('data:image');

              showDialog(
                context: context,
                builder: (_) => AlertDialog(
                  title: Text(isImage ? 'ğŸ¨ ØµÙˆØ±Ø© ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§' : 'ğŸ¤– Ø±Ø¯ Gemini'),
                  content: isImage
                      ? Image.memory(
                          base64Decode(response.split(',').last),
                        )
                      : Text(response),
                ),
              );
            }
          } else {
            // Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙ„Ø§Ø­ÙŠØ© Ø£Ùˆ Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŒ Ù†ÙˆÙ‚Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ùˆ ÙÙŠÙ‡ Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹Ù„Ù‚Ø©
            await speechToText.stop();
          }
        },
        backgroundColor: Pallete.firstSuggestionBoxColor,
        child: Icon(Icons.mic),
      ),
    );
  }
}
